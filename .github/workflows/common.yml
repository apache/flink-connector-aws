################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

on:
  workflow_call:
    inputs:
      flink_url:
        description: "Url to Flink binary."
        required: true
        type: string
      flink_version:
        description: "Flink version to test against."
        required: true
        type: string
      jdk_version:
        description: "Jdk version to test against."
        required: false
        default: 8, 11
        type: string
      cache_flink_binary:
        description: "Whether to cache the Flink binary. Should be false for SNAPSHOT URLs, true otherwise."
        required: true
        type: boolean
      timeout_global:
        description: "The timeout in minutes for the entire workflow."
        required: false
        type: number
        default: 60
      timeout_test:
        description: "The timeout in minutes for the compile and test step."
        required: false
        type: number
        default: 50

jobs:
  compile_and_test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        jdk: ${{ fromJSON(format('[{0}]', inputs.jdk_version)) }}
    timeout-minutes: ${{ inputs.timeout_global }}
    env:
      MVN_COMMON_OPTIONS: -U -B --no-transfer-progress -Dflink.version=${{ inputs.flink_version }}
      MVN_CONNECTION_OPTIONS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.httpconnectionManager.ttlSeconds=120
      FLINK_CACHE_DIR: "/tmp/cache/flink"
      MVN_BUILD_OUTPUT_FILE: "/tmp/mvn_build_output.out"
      MVN_VALIDATION_DIR: "/tmp/flink-validation-deployment"
      FLINK_AWS_USER: ${{ secrets.FLINK_AWS_USER }}
      FLINK_AWS_PASSWORD: ${{ secrets.FLINK_AWS_PASSWORD }}
      HAS_AWS_CREDS: ${{ secrets.FLINK_AWS_USER != '' && secrets.FLINK_AWS_PASSWORD != '' }}
    steps:
      - run: echo "Running CI pipeline for JDK version ${{ matrix.jdk }}"

      - name: Check out repository code
        uses: actions/checkout@v3

      - name: Set JDK
        uses: actions/setup-java@v3
        with:
          java-version: ${{ matrix.jdk }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Set Maven 3.8.5
        uses: stCarolas/setup-maven@v4.5
        with:
          maven-version: 3.8.5

      - name: Create cache dirs
        run: mkdir -p ${{ env.FLINK_CACHE_DIR }}

      - name: Cache Flink binary
        if: ${{ inputs.cache_flink_binary }}
        uses: actions/cache@v3
        id: cache-flink
        with:
          path: ${{ env.FLINK_CACHE_DIR }}
          key: ${{ inputs.flink_url }}

      - name: Download Flink binary
        working-directory: ${{ env.FLINK_CACHE_DIR }}
        if: steps.cache-flink.outputs.cache-hit != 'true'
        run: wget -q -c ${{ inputs.flink_url }} -O - | tar -xz

      - name: Compile and test flink-connector-aws
        timeout-minutes: ${{ inputs.timeout_test }}
        run: |
          set -o pipefail

          mvn clean install -Dflink.convergence.phase=install -Pcheck-convergence -U -B ${{ env.MVN_CONNECTION_OPTIONS }} \
            -DaltDeploymentRepository=validation_repository::default::file:${{ env.MVN_VALIDATION_DIR }} \
            -Dflink.version=${{ inputs.flink_version }} | tee ${{ env.MVN_BUILD_OUTPUT_FILE }}

      - name: Run e2e tests
        run: |
          set -o pipefail

          cd flink-connector-aws-e2e-tests

          mvn clean verify ${{ env.MVN_CONNECTION_OPTIONS }} \
            -DaltDeploymentRepository=validation_repository::default::file:${{ env.MVN_VALIDATION_DIR }} \
            -Dflink.version=${{ inputs.flink_version }}  \
            -Prun-end-to-end-tests -DdistDir=${{ env.FLINK_CACHE_DIR }}/flink-${{ inputs.flink_version }} \
            | tee ${{ env.MVN_BUILD_OUTPUT_FILE }}

          mvn clean

      - name: Run AWS e2e tests
        if: env.HAS_AWS_CREDS == 'true'
        run: |
          set -o pipefail

          cd flink-connector-aws-e2e-tests

          mvn clean verify ${{ env.MVN_CONNECTION_OPTIONS }} \
            -DaltDeploymentRepository=validation_repository::default::file:${{ env.MVN_VALIDATION_DIR }} \
            -Dflink.version=${{ inputs.flink_version }}  \
            -Prun-aws-end-to-end-tests -DdistDir=${{ env.FLINK_CACHE_DIR }}/flink-${{ inputs.flink_version }} \
            | tee ${{ env.MVN_BUILD_OUTPUT_FILE }}

          mvn clean

      - name: Check licensing
        run: |
          mvn ${MVN_COMMON_OPTIONS} exec:java@check-license -N \
            -Dexec.args="${{ env.MVN_BUILD_OUTPUT_FILE }} $(pwd) $(pwd)" \
            ${{ env.MVN_CONNECTION_OPTIONS }} \
            -Dlog4j.configurationFile=file://$(pwd)/tools/ci/log4j.properties
